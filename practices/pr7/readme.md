# Практическая работа №7

**Редукция и сканирование на GPU (CUDA, C++)**

## Цель работы

Изучить принципы реализации параллельных алгоритмов **редукции** и **префиксной суммы (scan)** на GPU с использованием технологии **CUDA**, а также сравнить производительность вычислений на CPU и GPU.

---

## Содержание работы

В рамках практической работы реализованы и протестированы следующие задачи:

---

### Задание 1 — Редукция (суммирование массива)

**Файл:** `task1_reduction.cu`

Реализован параллельный алгоритм редукции для вычисления суммы элементов массива на GPU.

**Что сделано:**

* Написано CUDA-ядро для суммирования элементов массива.
* Использована **разделяемая память (shared memory)** для ускорения доступа к данным.
* Выполнено суммирование внутри блоков с последующей агрегацией на CPU.
* Результат GPU сравнивается с результатом CPU для проверки корректности.

---

### Задание 2 — Префиксная сумма (scan)

**Файл:** `task2_scan.cu`

Реализован алгоритм вычисления **префиксной суммы (inclusive scan)** на GPU.

**Что сделано:**

* Реализовано CUDA-ядро префиксной суммы внутри одного блока.
* Использована **разделяемая память**.
* Алгоритм основан на схеме Hillis–Steele.
* Проведена проверка корректности результата на тестовом массиве.

---

### Задание 3 — Анализ производительности

**Файл:** `task3_benchmark.cu`

Проведено сравнение времени выполнения вычислений на CPU и GPU.

**Что сделано:**

* Реализовано измерение времени выполнения GPU-кода с помощью `cudaEvent`.
* Реализовано измерение времени выполнения CPU-кода с помощью `std::chrono`.
* Сравнено время выполнения простых вычислений на CPU и GPU.
* Показано преимущество GPU при параллельных вычислениях.

---

## Используемые технологии

* Язык программирования: **C++**
* Параллельные вычисления: **CUDA**
* Типы памяти CUDA:

  * глобальная память
  * разделяемая память (shared memory)

---

## Результаты

* Реализованы рабочие версии алгоритмов редукции и префиксной суммы на GPU.
* Подтверждена корректность вычислений путём сравнения с CPU-реализациями.
* Показано, что GPU обеспечивает более высокую производительность при параллельных вычислениях.

---

## Выводы

В ходе работы были изучены базовые параллельные алгоритмы редукции и сканирования, а также принципы оптимизации GPU-кода с использованием разделяемой памяти. Практика показала эффективность GPU при обработке массивов данных по сравнению с последовательными вычислениями на CPU.
