# Assignment 4  
Гибридные и распределённые параллельные вычисления

## Цель работы
Изучить методы реализации и анализа параллельных вычислений с использованием
CUDA, гибридного подхода CPU + GPU и распределённых вычислений на основе MPI.
Провести сравнение производительности различных подходов.

---

## Среда выполнения

Работа выполнена и протестирована в среде:

- Google Colab (Linux)
- NVIDIA CUDA
- OpenMP
- MPI (OpenMPI)

Особенности среды Google Colab:
- программы запускаются от имени пользователя `root`;
- ограниченное количество CPU-ядер;
- MPI используется с одним процессом или в режиме `oversubscribe`.


---

## Описание заданий

### Задание 1 — CUDA: сумма элементов массива

**Файл:** `task1_cuda_sum.cu`

Реализована CUDA-программа для вычисления суммы элементов массива с
использованием глобальной памяти GPU.

- Размер массива: 100 000 элементов
- Выполнено сравнение с последовательной реализацией на CPU
- Проведено измерение времени выполнения на CPU и GPU

---

### Задание 2 — CUDA: префиксная сумма (scan)

**Файл:** `task2_scan_shared.cu`

Реализован алгоритм префиксной суммы (сканирования) с использованием
разделяемой памяти GPU.

- Используется shared memory
- Реализован учебный вариант сканирования внутри одного блока
- Выполнено сравнение времени выполнения с CPU-реализацией

---

### Задание 3 — Гибридная обработка CPU + GPU

**Файл:** `task3_hybrid.cpp`

Реализована гибридная программа, в которой обработка массива выполняется
одновременно на CPU и GPU.

- Первая часть массива обрабатывается на CPU
- Вторая часть массива обрабатывается на GPU
- Сравниваются времена выполнения CPU-, GPU- и гибридной реализаций

---

### Задание 4 — Распределённые вычисления (MPI)

**Файл:** `task4_mpi.cpp`

Реализована распределённая программа для обработки массива данных с
использованием MPI.

- Массив разделяется между MPI-процессами
- Вычисления выполняются локально
- Результаты собираются с помощью `MPI_Reduce`
- Проведены замеры времени выполнения для различного числа процессов

---

## Компиляция и запуск в Google Colab

### Установка MPI
```bash
apt update
apt install -y openmpi-bin libopenmpi-dev
```
task1:
nvcc -O3 task1_cuda_sum.cu -o task1
./task1

task2:
nvcc -O3 task2_scan_shared.cu -o task2
./task2

task3:
nvcc -O3 task3_hybrid.cpp -o task3
./task3

task4:
mpic++ -O3 task4_mpi.cpp -o task4
mpirun --allow-run-as-root -np 1 ./task4

mpirun --allow-run-as-root --oversubscribe -np 4 ./task4

### Выводы

В ходе выполнения Assignment 4 были реализованы и протестированы различные
подходы к параллельным вычислениям: GPU-вычисления, гибридные CPU + GPU и
распределённые MPI-программы. Эксперименты показали, что выбор подхода зависит
от объёма данных, архитектуры системы и накладных расходов на передачу данных
и синхронизацию.